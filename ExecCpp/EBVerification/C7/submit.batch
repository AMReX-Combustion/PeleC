#!/bin/bash

#SBATCH --job-name=c7
#SBATCH --account=exact
#SBATCH --nodes=4
#SBATCH --time=4:00:00
#SBATCH -o %x.o%j

module purge
MODULES=modules
module unuse ${MODULEPATH}
module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}
module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}
module use /nopt/nrel/ecom/hpacf/software/${MODULES}/gcc-7.4.0

module load gcc
module load git
module load mpich

ranks_per_node=36
mpi_ranks=$(expr $SLURM_JOB_NUM_NODES \* $ranks_per_node)
export OMP_NUM_THREADS=1  # Max hardware threads = 4
export OMP_PLACES=threads
export OMP_PROC_BIND=spread

echo "Job name       = $SLURM_JOB_NAME"
echo "Num. nodes     = $SLURM_JOB_NUM_NODES"
echo "Num. MPI Ranks = $mpi_ranks"
echo "Num. threads   = $OMP_NUM_THREADS"
echo "Working dir    = $PWD"

paren=`pwd`
pelec="${paren}/PeleC3d.gnu.MPI.ex"

lev=( 0 1 2 )
for i in "${lev[@]}"
do
    rm -rf "${i}"
    mkdir "${i}"
    cd "${i}" || exit
    cp "${paren}/inputs_3d" .
    srun -n ${mpi_ranks} "${pelec}" inputs_3d `python3 ${paren}/gen_tube_input.py -a 30.0 -n 8` amr.max_level="${i}" pelec.eb_small_vfrac=0.015 > out
    ls -1v *plt*/Header | tee movie.visit
    cd "${paren}" || exit
done
