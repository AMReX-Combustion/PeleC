#!/bin/bash

#SBATCH --job-name=c10
#SBATCH --account=exact
#SBATCH --nodes=1
#SBATCH --time=4:00:00
#SBATCH -o %x.o%j

module purge
MODULES=modules
module unuse ${MODULEPATH}
module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}
module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}
module use /nopt/nrel/ecom/hpacf/software/${MODULES}/gcc-7.4.0

module load gcc
module load git
module load mpich

ranks_per_node=36
mpi_ranks=$(expr $SLURM_JOB_NUM_NODES \* $ranks_per_node)
export OMP_NUM_THREADS=1  # Max hardware threads = 4
export OMP_PLACES=threads
export OMP_PROC_BIND=spread

echo "Job name       = $SLURM_JOB_NAME"
echo "Num. nodes     = $SLURM_JOB_NUM_NODES"
echo "Num. MPI Ranks = $mpi_ranks"
echo "Num. threads   = $OMP_NUM_THREADS"
echo "Working dir    = $PWD"

paren=`pwd`
pelec="${paren}/PeleC3d.gnu.MPI.ex"

res=( 4 8 16 32 )
for i in "${res[@]}"
do
    rm -rf "${i}"
    mkdir "${i}"
    cd "${i}" || exit
    cp "${paren}/inputs_3d" .
    ny="$((i*4))"
    nx="$((i*4*3))"
    srun -n ${mpi_ranks} "${pelec}" inputs_3d amr.n_cell="${nx} ${ny} ${ny}" > out
    ls -1v *plt*/Header | tee movie.visit
    cd "${paren}" || exit
done
