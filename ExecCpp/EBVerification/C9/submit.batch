#!/bin/bash

#SBATCH --job-name=c9
#SBATCH --account=exact
#SBATCH --nodes=1
#SBATCH --time=4:00:00
#SBATCH -o %x.o%j

module purge
MODULES=modules-2020-07
COMPILER=gcc-8.4.0 #MPT 2.22
module unuse ${MODULEPATH}
module use /nopt/nrel/ecom/hpacf/binaries/${MODULES}
module use /nopt/nrel/ecom/hpacf/compilers/${MODULES}
module use /nopt/nrel/ecom/hpacf/utilities/${MODULES}
module use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}

module load gcc
module load git
module load mpt

ranks_per_node=36
mpi_ranks=$(expr $SLURM_JOB_NUM_NODES \* $ranks_per_node)
export OMP_NUM_THREADS=1  # Max hardware threads = 4
export OMP_PLACES=threads
export OMP_PROC_BIND=spread

echo "Job name       = $SLURM_JOB_NAME"
echo "Num. nodes     = $SLURM_JOB_NUM_NODES"
echo "Num. MPI Ranks = $mpi_ranks"
echo "Num. threads   = $OMP_NUM_THREADS"
echo "Working dir    = $PWD"

paren=`pwd`
pelec="${paren}/PeleC3d.gnu.MPI.ex"

res=( 8 16 32 64 )
for i in "${res[@]}"
do
    rm -rf "${i}"
    mkdir "${i}"
    cd "${i}" || exit
    cp "${paren}/inputs_3d" .
    srun -n ${mpi_ranks} "${pelec}" inputs_3d amr.n_cell="${i} ${i} ${i}" > out
    ls -1v *plt*/Header | tee movie.visit
    cd "${paren}" || exit
done
